{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F \n",
    "from torchvision import models, transforms\n",
    "\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Model and Sample Image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img_path):\n",
    "    \n",
    "    \"\"\"Load and process image\"\"\"\n",
    "    \n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "    #Transforms used by imagenet models\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.465, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    return transform(img).unsqueeze(0)\n",
    "\n",
    "def display_output(output, n=5):\n",
    "\n",
    "    \"\"\"Display the top categories predicted by the model.\"\"\"\n",
    "\n",
    "    #Catagories Download\n",
    "    url = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
    "    urllib.request.urlretrieve(url, \"imagenet_classes.txt\")\n",
    "\n",
    "    with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "        categories = [s.strip() for s in f.readlines()]\n",
    "\n",
    "    #Show top categories per image \n",
    "    prob = torch.nn.functional.softmax(output[0], dim = 0)\n",
    "    top_prob, top_cat = torch.topk(prob, n)\n",
    "\n",
    "    for i in range (top_prob.size(0)):\n",
    "        print(categories[top_cat[i]], top_prob[i].item())\n",
    "\n",
    "    return top_cat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load image\n",
    "img_path = \"/home/irfan/Guided-Backpropagation/n01491361_tiger_shark.JPEG\"\n",
    "img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load pre-traind model\n",
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess the image\n",
    "orig_img_tn = process_image(img_path)\n",
    "orig_img_tn = orig_img_tn.to(device)\n",
    "\n",
    "#Clone the tensor and enable gradient tracking\n",
    "img_tensor = orig_img_tn.clone()\n",
    "img_tensor.requires_grad_() \n",
    "\n",
    "pred = model(img_tensor)\n",
    "\n",
    "display_output(pred, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset gradient\n",
    "model.zero_grad()\n",
    "\n",
    "#select class with the highest probability\n",
    "target_class = pred.argmax()\n",
    "\n",
    "#compute gradient w.r.t. to logit y performing backward pass\n",
    "pred[:, target_class].backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the gradients\n",
    "standard_backprop_grads = img_tensor.grad.detach().cpu().numpy()\n",
    "print(standard_backprop_grads.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_grad(grads_in, activation=\"None\", skew=True, normalize=True, greyscale=False):\n",
    "\n",
    "    \"\"\"Process the gradeint for visualization\"\"\"\n",
    "\n",
    "    #copy the gradients\n",
    "    grads = np.copy(grads_in)\n",
    "\n",
    "    #Transpose the gradients\n",
    "    if len(grads.shape) >= 3:\n",
    "        grads = np.transpose(grads, (1,2,0))\n",
    "\n",
    "    #Get the absolute value of the gradients\n",
    "    if activation == \"relu\":\n",
    "        grads = np.maximum(0, grads)\n",
    "    elif activation == \"abs\":\n",
    "        grads = np.abs(grads)\n",
    "    else:\n",
    "        grads = grads\n",
    "\n",
    "    #normalize the gradients\n",
    "    if normalize:\n",
    "        grads -= np.min(grads)\n",
    "        grads /= (np.max(grads)+1.e-9)\n",
    "\n",
    "    #skew the gradients\n",
    "    if skew:\n",
    "        grads = np.sqrt(grads)\n",
    "\n",
    "    #convert the gradients to greyscale\n",
    "    if greyscale:\n",
    "        grads = np.mean(grads, axis=-1)\n",
    "\n",
    "    return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = standard_backprop_grads[0]\n",
    "\n",
    "#process the gradients\n",
    "relu_grads = process_grad(grads, activation=\"relu\")\n",
    "abs_grads = process_grad(grads, activation=\"abs\")\n",
    "grey_grad = process_grad(grads, greyscale=True, skew=False)\n",
    "\n",
    "\n",
    "# create subplots\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "\n",
    "# display gradients as images\n",
    "ax[0].imshow(relu_grads)\n",
    "ax[0].set_title(\"ReLU\")\n",
    "ax[0].axis(\"off\")\n",
    "\n",
    "ax[1].imshow(abs_grads)\n",
    "ax[1].set_title(\"Abs\")\n",
    "ax[1].axis(\"off\")\n",
    "\n",
    "ax[2].imshow(grey_grad, cmap=\"coolwarm\")\n",
    "ax[2].set_title(\"Greyscale\")\n",
    "ax[2].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace all in-place ReLu activation with out-of-place ones\n",
    "def replace_relu(model):\n",
    "    for name, child in model.named_children():\n",
    "        if isinstance(child, torch.nn.ReLU):\n",
    "            setattr(model, name, torch.nn.ReLU(inplace=False))\n",
    "            print(f\"Replcaing ReLU in layer: {name}\")\n",
    "        else:\n",
    "            replace_relu(child)\n",
    "\n",
    "replace_relu(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict to store gradeint\n",
    "gradients = {}\n",
    "\n",
    "def relu_hook(module, grad_in, grad_out, layer_name):\n",
    "    \"\"\"Guided Backprop Hook\"\"\"\n",
    "    modified_grad = []\n",
    "    \n",
    "    for g in grad_in:\n",
    "        if g is not None:\n",
    "            modified_grad.append(torch.clamp(g, min=0.0))\n",
    "        else: \n",
    "            modified_grad.append(None)\n",
    "\n",
    "    #save gradients \n",
    "    gradients[layer_name] = modified_grad[0].detach().cpu().numpy().squeeze()\n",
    "\n",
    "    return tuple(modified_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hook for all layers\n",
    "for name, layer in model.named_modules():\n",
    "\n",
    "    if isinstance(layer, torch.nn.ReLU):\n",
    "        layer.register_backward_hook(lambda m, gi, go, n=name: relu_hook(m, gi, go, n))\n",
    "        print(f\"ReLU hook registed for {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Guided backprop for target logit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset gradient \n",
    "img_tensor = orig_img_tn.clone()\n",
    "img_tensor.requires_grad_()\n",
    "model.zero_grad()\n",
    "\n",
    "#models prediction\n",
    "pred = model(img_tensor)\n",
    "\n",
    "#select class with highest score\n",
    "target_class = pred.argmax()\n",
    "\n",
    "#compute gradient w.r.t. to logit y performing backward pass\n",
    "pred[:, target_class].backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = img_tensor.grad.detach().cpu().numpy().squeeze()\n",
    "\n",
    "#process the gradients\n",
    "grads = process_grad(grads, activation=\"relu\")\n",
    "\n",
    "\n",
    "# create subplots\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# display gradients as images\n",
    "ax[0].imshow(relu_grads)\n",
    "ax[0].set_title(\"Standard Backprop\")\n",
    "ax[0].axis(\"off\")\n",
    "\n",
    "ax[1].imshow(grads)\n",
    "ax[1].set_title(\"Guided_packprop\")\n",
    "ax[1].axis(\"off\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Guided Backprop from intermediate layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#radients from the first layer\n",
    "layer = 'features.1'\n",
    "\n",
    "#get gradeints for all feature map in layer\n",
    "layer_grads = gradients[layer]\n",
    "print(layer_grads.shape)\n",
    "\n",
    "#select a random feature map\n",
    "i = np.random.randint(0, layer_grads.shape[0])\n",
    "feature_map_grads = layer_grads[i]\n",
    "\n",
    "#processing the gradients \n",
    "feature_map_grads = process_grad(feature_map_grads)\n",
    "\n",
    "#display the gradient\n",
    "plt.imshow(feature_map_grads, cmap='coolwarm')\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4,5, figsize=(15,15))\n",
    "\n",
    "for i, layer in enumerate(['features.1', 'features.6', 'features.13', 'features.22']):\n",
    "    layer_grads = gradients[layer]\n",
    "    print(f\"{layer}: {layer_grads.shape}\")\n",
    "\n",
    "    for j in range(5):\n",
    "        n_features = layer_grads.shape[0]\n",
    "        r = np.random.randint(0, n_features)\n",
    "\n",
    "        feature_map_grads = layer_grads[r]\n",
    "        feature_map_grads = process_grad(feature_map_grads)\n",
    "\n",
    "        ax[i,j].imshow(feature_map_grads, cmap=\"coolwarm\")\n",
    "        ax[i,j].set_title(f\"{r} of {n_features}\")\n",
    "        ax[i,j].set_xticks([])\n",
    "        ax[i,j].set_yticks([])\n",
    "\n",
    "    ax[i,0].set_ylabel(f\"{layer}\", fontsize = 15)\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
